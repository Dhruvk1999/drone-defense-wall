{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f6bfa2",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "\n",
    "two methods:\n",
    "* Detect a moving object - Optical Flow \n",
    "* Detect drone purely from image processing -- not working\n",
    "* deep learning\n",
    "\n",
    "## for the second approach\n",
    "\n",
    "\n",
    "* try watershed algorithm  -- didn't get good results\n",
    "* try corner detection  -- satisfactory results --not so much\n",
    "\n",
    "* ensemble of both\n",
    "\n",
    "* grabCut\n",
    "\n",
    "*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d593dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d77844",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde791dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd drone-defense-wall/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34840100",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"data/drone.jpg\")\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b79fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_img=cv2.medianBlur(img,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(blur_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img=cv2.cvtColor(blur_img,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c8544",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gray_img,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8275d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120416f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,sep_thresh=cv2.threshold(gray_img,160,255,cv2.THRESH_BINARY_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15298ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sep_thresh,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ae4bbe",
   "metadata": {},
   "source": [
    "# Corner Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ca406",
   "metadata": {},
   "outputs": [],
   "source": [
    "drone=img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf2ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_drone=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc45798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gray_drone,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8abacad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do this on the actual image\n",
    "\n",
    "gray=np.float32(gray_drone)\n",
    "\n",
    "#corner_harris_detection \n",
    "dst=cv2.cornerHarris(src=gray,blockSize=2,ksize=3,k=0.04)\n",
    "\n",
    "#reusly is dilated for marking the corners, not important for actual corner deetection\n",
    "# this is just so we can plot out the points on the image\n",
    "dst=cv2.dilate(dst,None)\n",
    "\n",
    "# threshold for an optimal value, it may vary depending on the image\n",
    "drone[dst>0.01*dst.max()]=[255,0,0]\n",
    "plt.imshow(drone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5518c08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dst,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d97774",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e8f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d3a940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a75a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d4321a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c6b114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58926996",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e742dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "  \n",
    "# path to input image specified and\n",
    "# image is loaded with imread command\n",
    "image = drones\n",
    "  \n",
    "# create a simple mask image similar\n",
    "# to the loaded image, with the\n",
    "# shape and return type\n",
    "mask = np.zeros(image.shape[:2], np.uint8)\n",
    "  \n",
    "# specify the background and foreground model\n",
    "# using numpy the array is constructed of 1 row\n",
    "# and 65 columns, and all array elements are 0\n",
    "# Data type for the array is np.float64 (default)\n",
    "backgroundModel = np.zeros((1, 65), np.float64)\n",
    "foregroundModel = np.zeros((1, 65), np.float64)\n",
    "  \n",
    "# define the Region of Interest (ROI)\n",
    "# as the coordinates of the rectangle\n",
    "# where the values are entered as\n",
    "# (startingPoint_x, startingPoint_y, width, height)\n",
    "# these coordinates are according to the input image\n",
    "# it may vary for different images\n",
    "rectangle = (20, 100, 150, 150)\n",
    "  \n",
    "# apply the grabcut algorithm with appropriate\n",
    "# values as parameters, number of iterations = 3\n",
    "# cv2.GC_INIT_WITH_RECT is used because\n",
    "# of the rectangle mode is used\n",
    "cv2.grabCut(image, mask, rectangle, \n",
    "            backgroundModel, foregroundModel,\n",
    "            3, cv2.GC_INIT_WITH_RECT)\n",
    "  \n",
    "# In the new mask image, pixels will\n",
    "# be marked with four flags\n",
    "# four flags denote the background / foreground\n",
    "# mask is changed, all the 0 and 2 pixels\n",
    "# are converted to the background\n",
    "# mask is changed, all the 1 and 3 pixels\n",
    "# are now the part of the foreground\n",
    "# the return type is also mentioned,\n",
    "# this gives us the final mask\n",
    "mask2 = np.where((mask == 2)|(mask == 0), 0, 1).astype('uint8')\n",
    "  \n",
    "# The final mask is multiplied with\n",
    "# the input image to give the segmented image.\n",
    "image = image * mask2[:, :, np.newaxis]\n",
    "  \n",
    "# output segmented image with colorbar\n",
    "plt.imshow(image)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b92747",
   "metadata": {},
   "source": [
    "# feature matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img,cmap='gray'):\n",
    "    fig = plt.figure(figsize=(18,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8731ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd drone-defense-wall/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d475c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('data/cropped_drone.jpg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2751782",
   "metadata": {},
   "outputs": [],
   "source": [
    "drones = cv2.imread('data/drone2.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SIFT detector\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img,None)\n",
    "kp2, des2 = sift.detectAndCompute(drones,None)\n",
    "\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)  \n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "# Need to draw only good matches, so create a mask\n",
    "matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "# ratio test\n",
    "for i,(match1,match2) in enumerate(matches):\n",
    "    if match1.distance < 0.7*match2.distance:\n",
    "        matchesMask[i]=[1,0]\n",
    "\n",
    "draw_params = dict(matchColor = (0,255,0),\n",
    "                   singlePointColor = (255,0,0),\n",
    "                   matchesMask = matchesMask,\n",
    "                   flags = 0)\n",
    "\n",
    "flann_matches = cv2.drawMatchesKnn(img,kp1,drones,kp2,matches,None,**draw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(flann_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36bfa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "img = drones\n",
    "mask = np.zeros(img.shape[:2],np.uint8)\n",
    "bgdModel = np.zeros((1,65),np.float64)\n",
    "fgdModel = np.zeros((1,65),np.float64)\n",
    "rect = (50,50,450,290)\n",
    "cv.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv.GC_INIT_WITH_RECT)\n",
    "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "img = img*mask2[:,:,np.newaxis]\n",
    "plt.imshow(img),plt.colorbar(),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945932c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(drones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d21aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd drone-defense-wall/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd2ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.VideoCapture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1972d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense optical flow\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "  \n",
    "  \n",
    "# The video feed is read in as\n",
    "# a VideoCapture object\n",
    "cap = cv.VideoCapture(\"cam0.mp4\")\n",
    "  \n",
    "# ret = a boolean return value from\n",
    "# getting the frame, first_frame = the\n",
    "# first frame in the entire video sequence\n",
    "ret, first_frame = cap.read()\n",
    "  \n",
    "# Converts frame to grayscale because we\n",
    "# only need the luminance channel for\n",
    "# detecting edges - less computationally \n",
    "# expensive\n",
    "prev_gray = cv.cvtColor(first_frame, cv.COLOR_BGR2GRAY)\n",
    "  \n",
    "# Creates an image filled with zero\n",
    "# intensities with the same dimensions \n",
    "# as the frame\n",
    "mask = np.zeros_like(first_frame)\n",
    "  \n",
    "# Sets image saturation to maximum\n",
    "mask[..., 1] = 255\n",
    "  \n",
    "while(cap.isOpened()):\n",
    "      \n",
    "    # ret = a boolean return value from getting\n",
    "    # the frame, frame = the current frame being\n",
    "    # projected in the video\n",
    "    ret, frame = cap.read()\n",
    "      \n",
    "    # Opens a new window and displays the input\n",
    "    # frame\n",
    "    cv.imshow(\"input\", frame)\n",
    "      \n",
    "    # Converts each frame to grayscale - we previously \n",
    "    # only converted the first frame to grayscale\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "      \n",
    "    # Calculates dense optical flow by Farneback method\n",
    "    flow = cv.calcOpticalFlowFarneback(prev_gray, gray, \n",
    "                                       None,\n",
    "                                       0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "      \n",
    "    # Computes the magnitude and angle of the 2D vectors\n",
    "    magnitude, angle = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "      \n",
    "    # Sets image hue according to the optical flow \n",
    "    # direction\n",
    "    mask[..., 0] = angle * 180 / np.pi / 2\n",
    "      \n",
    "    # Sets image value according to the optical flow\n",
    "    # magnitude (normalized)\n",
    "    mask[..., 2] = cv.normalize(magnitude, None, 0, 255, cv.NORM_MINMAX)\n",
    "      \n",
    "    # Converts HSV to RGB (BGR) color representation\n",
    "    rgb = cv.cvtColor(mask, cv.COLOR_HSV2BGR)\n",
    "      \n",
    "    # Opens a new window and displays the output frame\n",
    "    plt.imshow(\"dense optical flow\", rgb)\n",
    "      \n",
    "    # Updates previous frame\n",
    "    prev_gray = gray\n",
    "      \n",
    "    # Frames are read by intervals of 1 millisecond. The\n",
    "    # programs breaks out of the while loop when the\n",
    "    # user presses the 'q' key\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "# The following frees up resources and\n",
    "# closes all windows\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "619c8f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dhruv\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "109c1066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dhruv/drone-defense-wall/data\n"
     ]
    }
   ],
   "source": [
    "cd drone-defense-wall/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c24fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dhruv\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ca628c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a.out                                       \u001b[0m\u001b[01;34mmomentum-trader\u001b[0m/\r\n",
      "\u001b[00;32m'big ass 8.pdf'\u001b[0m                              \u001b[01;34mMusic\u001b[0m/\r\n",
      " \u001b[01;34mDesktop\u001b[0m/                                    \u001b[01;34mopenCV-practice\u001b[0m/\r\n",
      " \u001b[00;32mdip_notes_with_love_dhruv.pdf\u001b[0m               \u001b[01;34mPictures\u001b[0m/\r\n",
      " \u001b[01;34mDocuments\u001b[0m/                                  \u001b[01;34mPublic\u001b[0m/\r\n",
      " \u001b[01;34mDownloads\u001b[0m/                                  \u001b[01;34mTemplates\u001b[0m/\r\n",
      " \u001b[01;34mdrone-defense-wall\u001b[0m/                         \u001b[01;34mtor-browser\u001b[0m/\r\n",
      " \u001b[01;34mdrone-detection\u001b[0m/                            Untitled1.ipynb\r\n",
      " \u001b[01;34mgoogle-chrome\u001b[0m/                              Untitled.ipynb\r\n",
      " happiest-minds-episode-2-stackroute.ipynb   \u001b[01;34mVideos\u001b[0m/\r\n",
      " \u001b[01;34mkilling-drones\u001b[0m/                             \u001b[01;34myay\u001b[0m/\r\n",
      " \u001b[01;34mmicrosoft-edge-stable-bin\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "862a34c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Region Proposals: 299\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "'''\n",
    "Usage:\n",
    "./ssearch.py input_image (f|q)\n",
    "f=fast, q=quality\n",
    "Use \"l\" to display less rects, 'm' to display more rects, \"q\" to quit.\n",
    "'''\n",
    "\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "\n",
    "# If image path and f/q is not passed as command\n",
    "# line arguments, quit and display help message\n",
    "if len(sys.argv) < 3:\n",
    "    print(__doc__)\n",
    "    sys.exit(1)\n",
    "\n",
    "# speed-up using multithreads\n",
    "cv2.setUseOptimized(True);\n",
    "cv2.setNumThreads(4);\n",
    "\n",
    "# read image\n",
    "im = cv2.imread(\"155.jpg\")\n",
    "# resize image\n",
    "newHeight = 200\n",
    "newWidth = int(im.shape[1]*200/im.shape[0])\n",
    "im = cv2.resize(im, (newWidth, newHeight))    \n",
    "\n",
    "# create Selective Search Segmentation Object using default parameters\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "\n",
    "# set input image on which we will run segmentation\n",
    "ss.setBaseImage(im)\n",
    "\n",
    "# Switch to fast but low recall Selective Search method\n",
    "#if (sys.argv[2] == 'f'):\n",
    "ss.switchToSelectiveSearchFast()\n",
    "\n",
    "# Switch to high recall but slow Selective Search method\n",
    "# elif (sys.argv[2] == 'q'):\n",
    "#     ss.switchToSelectiveSearchQuality()\n",
    "# # if argument is neither f nor q print help message\n",
    "# else:\n",
    "#     print(__doc__)\n",
    "#     sys.exit(1)\n",
    "\n",
    "# run selective search segmentation on input image\n",
    "rects = ss.process()\n",
    "print('Total Number of Region Proposals: {}'.format(len(rects)))\n",
    "\n",
    "# number of region proposals to show\n",
    "numShowRects = 100\n",
    "# increment to increase/decrease total number\n",
    "# of reason proposals to be shown\n",
    "increment = 50\n",
    "\n",
    "while True:\n",
    "    # create a copy of original image\n",
    "    imOut = im.copy()\n",
    "\n",
    "    # itereate over all the region proposals\n",
    "    for i, rect in enumerate(rects):\n",
    "        # draw rectangle for region proposal till numShowRects\n",
    "        if (i < numShowRects):\n",
    "            x, y, w, h = rect\n",
    "            cv2.rectangle(imOut, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # show output\n",
    "    cv2.imshow(\"Output\", imOut)\n",
    "\n",
    "    # record key press\n",
    "    k = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "    # m is pressed\n",
    "    if k == 109:\n",
    "        # increase total number of rectangles to show by increment\n",
    "        numShowRects += increment\n",
    "    # l is pressed\n",
    "    elif k == 108 and numShowRects > increment:\n",
    "        # decrease total number of rectangles to show by increment\n",
    "        numShowRects -= increment\n",
    "    # q is pressed\n",
    "    elif k == 113:\n",
    "        break\n",
    "# close image show window\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0ff146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
