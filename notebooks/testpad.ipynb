{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61279c28",
   "metadata": {},
   "source": [
    "# Some tutorials\n",
    "<a href=\"https://towardsdatascience.com/object-detection-explained-r-cnn-a6c813937a76\"> region proposal using r-cnn</a>\n",
    "\n",
    "<a href=\"https://learnopencv.com/selective-search-for-object-detection-cpp-python/\"> region proposal using selective segmentation</a>\n",
    "\n",
    "https://github.com/chingisooinar/Object-Detection_from-Scratch/blob/main/RCNN/RCNN.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e562805b",
   "metadata": {},
   "source": [
    "# Selective selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2058ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dhruv\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "edd1c800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dhruv'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ae5478d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dhruv/drone-defense-wall/data\n"
     ]
    }
   ],
   "source": [
    "cd drone-defense-wall/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2d4ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9c219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Region Proposals: 119\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "'''\n",
    "Usage:\n",
    "./ssearch.py input_image (f|q)\n",
    "f=fast, q=quality\n",
    "Use \"l\" to display less rects, 'm' to display more rects, \"q\" to quit.\n",
    "'''\n",
    "\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "\n",
    "# If image path and f/q is not passed as command\n",
    "# line arguments, quit and display help message\n",
    "if len(sys.argv) < 3:\n",
    "    print(__doc__)\n",
    "    sys.exit(1)\n",
    "\n",
    "# speed-up using multithreads\n",
    "cv2.setUseOptimized(True);\n",
    "cv2.setNumThreads(4);\n",
    "\n",
    "# read image\n",
    "im = cv2.imread(\"194.jpg\")\n",
    "# resize image\n",
    "newHeight = 200\n",
    "newWidth = int(im.shape[1]*200/im.shape[0])\n",
    "im = cv2.resize(im, (newWidth, newHeight))    \n",
    "\n",
    "# create Selective Search Segmentation Object using default parameters\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "\n",
    "# set input image on which we will run segmentation\n",
    "ss.setBaseImage(im)\n",
    "\n",
    "# Switch to fast but low recall Selective Search method\n",
    "#if (sys.argv[2] == 'f'):\n",
    "ss.switchToSelectiveSearchFast()\n",
    "\n",
    "# Switch to high recall but slow Selective Search method\n",
    "# elif (sys.argv[2] == 'q'):\n",
    "#     ss.switchToSelectiveSearchQuality()\n",
    "# # if argument is neither f nor q print help message\n",
    "# else:\n",
    "#     print(__doc__)\n",
    "#     sys.exit(1)\n",
    "\n",
    "# run selective search segmentation on input image\n",
    "rects = ss.process()\n",
    "\n",
    "# taking only the upper 2/3rd of the image\n",
    "bboxes=[]\n",
    "for x,y,w,h in rects:\n",
    "    if y<100:\n",
    "        bboxes.append([x,y,w,h])\n",
    "bboxes=np.array(bboxes)\n",
    "rects=bboxes\n",
    "print('Total Number of Region Proposals: {}'.format(len(rects)))\n",
    "\n",
    "# number of region proposals to show\n",
    "numShowRects = 80\n",
    "# increment to increase/decrease total number\n",
    "# of reason proposals to be shown\n",
    "increment = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    # create a copy of original image\n",
    "    imOut = im.copy()\n",
    "\n",
    "    # itereate over all the region proposals\n",
    "    for i, rect in enumerate(rects):\n",
    "        # draw rectangle for region proposal till numShowRects\n",
    "        if (i < numShowRects):\n",
    "            x, y, w, h = rect\n",
    "            cv2.rectangle(imOut, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # show output\n",
    "    cv2.imshow(\"Output\", imOut)\n",
    "\n",
    "    # record key press\n",
    "    k = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "    # m is pressed\n",
    "    if k == 109:\n",
    "        # increase total number of rectangles to show by increment\n",
    "        numShowRects += increment\n",
    "    # l is pressed\n",
    "    elif k == 108 and numShowRects > increment:\n",
    "        # decrease total number of rectangles to show by increment\n",
    "        numShowRects -= increment\n",
    "    # q is pressed\n",
    "    elif k == 113:\n",
    "        break\n",
    "# close image show window\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedd0af5",
   "metadata": {},
   "source": [
    "# Object Tracking\n",
    "- using boosting and median tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d53addcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dhruv\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6662f604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dhruv/openCV-practice/Computer-Vision-with-Python\n"
     ]
    }
   ],
   "source": [
    "cd openCV-practice/Computer-Vision-with-Python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf1b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_for_tracker():\n",
    "    print(\"Welcome! What Tracker API would you like to use?\")\n",
    "    print(\"Enter 0 for BOOSTING: \")\n",
    "    print(\"Enter 1 for MIL: \")\n",
    "    print(\"Enter 2 for KCF: \")\n",
    "    print(\"Enter 3 for TLD: \")\n",
    "    print(\"Enter 4 for MEDIANFLOW: \")\n",
    "    choice = input(\"Please select your tracker: \")\n",
    "    \n",
    "    if choice == '0':\n",
    "        tracker = cv2.legacy.TrackerBoosting_create()\n",
    "    if choice == '1':\n",
    "        tracker = cv2.legacy.TrackerMIL_create()\n",
    "    if choice == '2':\n",
    "        tracker = cv2.legacy.TrackerKCF_create()\n",
    "    if choice == '3':\n",
    "        tracker = cv2.legacy.TrackerTLD_create()\n",
    "    if choice == '4':\n",
    "        tracker = cv2.legacy.TrackerMedianFlow_create()\n",
    "\n",
    "\n",
    "    return tracker\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a54d5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! What Tracker API would you like to use?\n",
      "Enter 0 for BOOSTING: \n",
      "Enter 1 for MIL: \n",
      "Enter 2 for KCF: \n",
      "Enter 3 for TLD: \n",
      "Enter 4 for MEDIANFLOW: \n",
      "Please select your tracker: 0\n",
      "(499, 277) and (553, 334)\n",
      "(499, 278) and (553, 335)\n",
      "(499, 279) and (553, 336)\n",
      "(498, 279) and (552, 336)\n",
      "(498, 280) and (552, 337)\n",
      "(498, 281) and (552, 338)\n",
      "(497, 281) and (551, 338)\n",
      "(497, 282) and (551, 339)\n",
      "(497, 283) and (551, 340)\n",
      "(496, 284) and (550, 341)\n",
      "(496, 284) and (550, 341)\n",
      "(495, 285) and (549, 342)\n",
      "(495, 285) and (549, 342)\n",
      "(495, 286) and (549, 343)\n",
      "(495, 287) and (549, 344)\n",
      "(494, 287) and (548, 344)\n",
      "(494, 288) and (548, 345)\n",
      "(495, 289) and (549, 346)\n",
      "(494, 289) and (548, 346)\n",
      "(494, 290) and (548, 347)\n",
      "(493, 290) and (547, 347)\n",
      "(493, 291) and (547, 348)\n",
      "(493, 292) and (547, 349)\n",
      "(493, 292) and (547, 349)\n",
      "(493, 293) and (547, 350)\n",
      "(493, 294) and (547, 351)\n",
      "(493, 294) and (547, 351)\n",
      "(493, 295) and (547, 352)\n",
      "(493, 295) and (547, 352)\n",
      "(493, 295) and (547, 352)\n",
      "(493, 296) and (547, 353)\n",
      "(492, 296) and (546, 353)\n",
      "(492, 297) and (546, 354)\n",
      "(493, 298) and (547, 355)\n",
      "(493, 298) and (547, 355)\n",
      "(492, 298) and (546, 355)\n",
      "(493, 299) and (547, 356)\n",
      "(492, 299) and (546, 356)\n",
      "(493, 300) and (547, 357)\n",
      "(493, 300) and (547, 357)\n",
      "(493, 300) and (547, 357)\n",
      "(493, 301) and (547, 358)\n",
      "(493, 301) and (547, 358)\n",
      "(493, 301) and (547, 358)\n",
      "(494, 302) and (548, 359)\n",
      "(494, 302) and (548, 359)\n",
      "(494, 302) and (548, 359)\n",
      "(494, 303) and (548, 360)\n",
      "(494, 303) and (548, 360)\n",
      "(495, 303) and (549, 360)\n",
      "(495, 303) and (549, 360)\n",
      "(495, 303) and (549, 360)\n",
      "(496, 304) and (550, 361)\n",
      "(496, 304) and (550, 361)\n",
      "(496, 304) and (550, 361)\n",
      "(496, 304) and (550, 361)\n",
      "(497, 304) and (551, 361)\n",
      "(497, 304) and (551, 361)\n",
      "(497, 304) and (551, 361)\n",
      "(497, 304) and (551, 361)\n",
      "(498, 304) and (552, 361)\n",
      "(498, 305) and (552, 362)\n",
      "(498, 305) and (552, 362)\n",
      "(499, 305) and (553, 362)\n",
      "(499, 305) and (553, 362)\n",
      "(499, 305) and (553, 362)\n",
      "(499, 305) and (553, 362)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "tracker = ask_for_tracker()\n",
    "tracker_name = str(tracker).split()[0][1:]\n",
    "\n",
    "# Read video\n",
    "cap = cv2.VideoCapture(\"DATA/cam0.mp4\")\n",
    "\n",
    "# Read first frame.\n",
    "ret, frame = cap.read()\n",
    "\n",
    "\n",
    "# Special function allows us to draw on the very first frame our desired ROI\n",
    "## replace this roi by the coordinates from the resultant image from the DL model resultant\n",
    "roi = cv2.selectROI(frame, False)\n",
    "\n",
    "# Initialize tracker with first frame and bounding box\n",
    "ret = tracker.init(frame, roi)\n",
    "\n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    # Update tracker\n",
    "    success, roi = tracker.update(frame)\n",
    "    \n",
    "    # roi variable is a tuple of 4 floats\n",
    "    # We need each value and we need them as integers\n",
    "    (x,y,w,h) = tuple(map(int,roi))\n",
    "    \n",
    "    # Draw Rectangle as Tracker moves\n",
    "    if success:\n",
    "        # Tracking success\n",
    "        p1 = (x, y)\n",
    "        p2 = (x+w, y+h)\n",
    "        cv2.rectangle(frame, p1, p2, (0,255,0), 3)\n",
    "        print(f'{p1} and {p2}')\n",
    "    else :\n",
    "        # Tracking failure\n",
    "        cv2.putText(frame, \"Failure to Detect Tracking!!\", (100,200), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),3)\n",
    "\n",
    "    # Display tracker type on frame\n",
    "    cv2.putText(frame, tracker_name, (20,400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0),3);\n",
    "\n",
    "    # Display result\n",
    "    cv2.imshow(tracker_name, frame)\n",
    "\n",
    "    # Exit if ESC pressed\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    if k == 27 : \n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f620db58",
   "metadata": {},
   "source": [
    "## To-do modifying the above code to take in corrdinates from the DL model resultant image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "717f2f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfdb1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified code\n",
    "import cv2\n",
    "tracker = ask_for_tracker()\n",
    "tracker_name = str(tracker).split()[0][1:]\n",
    "\n",
    "# Read video\n",
    "cap = cv2.VideoCapture(\"DATA/cam0.mp4\")\n",
    "\n",
    "# Read first frame.\n",
    "ret, frame = cap.read()\n",
    "\n",
    "\n",
    "# Special function allows us to draw on the very first frame our desired ROI\n",
    "## replace this roi by the coordinates from the resultant image from the DL model resultant\n",
    "roi = cv2.selectROI(frame, False)\n",
    "\n",
    "# Initialize tracker with first frame and bounding box\n",
    "ret = tracker.init(frame, roi)\n",
    "\n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    # Update tracker\n",
    "    success, roi = tracker.update(frame)\n",
    "    \n",
    "    # roi variable is a tuple of 4 floats\n",
    "    # We need each value and we need them as integers\n",
    "    (x,y,w,h) = tuple(map(int,roi))\n",
    "    \n",
    "    # Draw Rectangle as Tracker moves\n",
    "    if success:\n",
    "        # Tracking success\n",
    "        p1 = (x, y)\n",
    "        p2 = (x+w, y+h)\n",
    "        cv2.rectangle(frame, p1, p2, (0,255,0), 3)\n",
    "        print(f'{p1} and {p2}')\n",
    "    else :\n",
    "        # Tracking failure\n",
    "        cv2.putText(frame, \"Failure to Detect Tracking!!\", (100,200), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),3)\n",
    "\n",
    "    # Display tracker type on frame\n",
    "    cv2.putText(frame, tracker_name, (20,400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0),3);\n",
    "\n",
    "    # Display result\n",
    "    cv2.imshow(tracker_name, frame)\n",
    "\n",
    "    # Exit if ESC pressed\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    if k == 27 : \n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e74c0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499.0, 305.0, 54.0, 57.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019613d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
